{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Use Keras Neural Network Components. This will be used to construct the LSTM\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.regularizers import L1L2\n",
    "\n",
    "#Import Tensorflow \n",
    "import tensorflow as tf\n",
    "\n",
    "#Plotting Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensure Reproducability of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch and Set Up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numerically Encode the Activities\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATDIR = \"data/UCI HAR Dataset\"\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test: 0 if we want to fetch the training signal data, 1 if we want to fetch the test signal data\n",
    "def fetch_raw_signal_data(train_test, signal):\n",
    "    file_path = DATDIR + f\"/{'train' if train_test == 0 else 'test'}/Inertial Signals/{signal}_{'train' if train_test == 0 else 'test'}.txt\"\n",
    "    return pd.read_csv(file_path, delim_whitespace = True, header = None)\n",
    "\n",
    "#Same purpose as previous function but, in this case, we are fetching ALL the raw signal data!\n",
    "#train_test: 0 if we want to fetch the training signal data, 1 if we want to fetch the test signal data\n",
    "def fetch_all_raw_signals(train_test):\n",
    "    data_raw_signals = []\n",
    "    for signal in SIGNALS:\n",
    "        raw_signal_data = fetch_raw_signal_data(train_test, signal).to_numpy()\n",
    "        data_raw_signals.append(raw_signal_data)\n",
    "    \n",
    "    data_raw_signals = np.array(data_raw_signals)\n",
    "    return np.transpose(data_raw_signals, axes = (1, 2, 0))\n",
    "\n",
    "#Fetch Labels\n",
    "#train_test: 0 if we want to fetch the training signal data, 1 if we want to fetch the test signal data\n",
    "def fetch_labels(train_test):\n",
    "    file_path = DATDIR + f\"/{'train' if train_test == 0 else 'test'}/y_{'train' if train_test == 0 else 'test'}.txt\"\n",
    "    return pd.get_dummies(pd.read_csv(file_path, delim_whitespace=True, header = None)[0]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = fetch_all_raw_signals(0), fetch_all_raw_signals(1), fetch_labels(0), fetch_labels(1)\n",
    "\n",
    "N = X_train.shape[0]\n",
    "T = X_train.shape[1]\n",
    "D = X_train.shape[2]\n",
    "\n",
    "print(N, T, D)\n",
    "\n",
    "n_classes = Y_train.shape[1]\n",
    "print(n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define LSTM Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use 1 LSTM Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Hyperparameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden_1 = 32\n",
    "n_hidden_2 = 16\n",
    "dropout_p = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() #Initializing our Model Architecture\n",
    "\n",
    "# Add an LSTM Layer\n",
    "model.add(LSTM(n_hidden_1, input_shape = (T, D)))\n",
    "\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(dropout_p))\n",
    "\n",
    "#Add another Dense Layer\n",
    "model.add(Dense(n_hidden_2, activation = \"relu\"))\n",
    "\n",
    "# Adding a Dense Layer with the Softmax Activation Function\n",
    "model.add(Dense(n_classes, activation = 'softmax'))\n",
    "\n",
    "model.summary() #Display a Summary of our model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, validation_data=(X_test, Y_test),epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Confusion Matrix\n",
    "confusion_matrix = generate_confusion_matrix(Y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Normalized Confusion Matrix\n",
    "\n",
    "# Calculate normalized confusion matrix\n",
    "normalized_cm = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "#List out target names\n",
    "target_names = ['LAYING', 'SITTING', 'STANDING', 'WALKING', 'WALKING_DOWNSTAIRS', 'WALKING_UPSTAIRS']\n",
    "\n",
    "#Use seaborn to plot heat map of confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(normalized_cm, annot=True, fmt='.2f', xticklabels = target_names, yticklabels = target_names)\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "\n",
    "print(\"\\n   cat_crossentropy  ||   accuracy \")\n",
    "print(\"  ____________________________________\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use 2 LSTM Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Hyperparameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden_1 = 64\n",
    "dropout_p = 0.5\n",
    "n_hidden_2 = 32\n",
    "n_hidden_3 = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() #Initializing our Model Architecture\n",
    "\n",
    "#Define LSTM Layer with Batch Normalization\n",
    "model.add(LSTM(n_hidden_1, input_shape=(T, D), return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#Define Dropout Layer\n",
    "model.add(Dropout(dropout_p))\n",
    "\n",
    "#Define the second LSTM Layer with Batch Normalization\n",
    "model.add(LSTM(n_hidden_2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#Define Dropout Layer\n",
    "model.add(Dropout(dropout_p))\n",
    "\n",
    "#Define Dense Layer\n",
    "model.add(Dense(n_hidden_3, activation = 'relu'))\n",
    "\n",
    "#Define Dense Layer\n",
    "model.add(Dense(n_classes, activation = 'softmax'))\n",
    "\n",
    "#Print Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, validation_data=(X_test, Y_test),epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Confusion Matrix\n",
    "confusion_matrix = generate_confusion_matrix(Y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Normalized Confusion Matrix\n",
    "\n",
    "# Calculate normalized confusion matrix\n",
    "normalized_cm = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "#List out target names\n",
    "target_names = ['LAYING', 'SITTING', 'STANDING', 'WALKING', 'WALKING_DOWNSTAIRS', 'WALKING_UPSTAIRS']\n",
    "\n",
    "#Use seaborn to plot heat map of confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(normalized_cm, annot=True, fmt='.2f', xticklabels = target_names, yticklabels = target_names)\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "\n",
    "print(\"\\n   cat_crossentropy  ||   accuracy \")\n",
    "print(\"  ____________________________________\")\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
